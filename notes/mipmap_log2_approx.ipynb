{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast $\\log_2$ approximation for trilinear mipmapping\n",
    "\n",
    "## Some definitions:\n",
    "\n",
    "- $(u, v)\\in [0, 1]^2$: the coordinate of the sample to be taken\n",
    "- $n$: the size of the full-resolution image.\n",
    "- $N = \\lfloor \\log_2 n \\rfloor + 1 $: the number of mip-map levels.\n",
    "- $f_k(u, v)$: the texture function for each mip-map level, with bilinear interpolation of the pixels.\n",
    "    - $f_0(u, v)$ is the original, full-resolution $n \\times n$ pixel image.\n",
    "    - $f_{N-1}(u, v)$ is the $1 \\times 1$ pixel image.\n",
    "- $w > 0$: the requested texel size, normalized on the texture size. I.e. this is the diameter of the sample to be taken from the texture.\n",
    "    - $w = 1$ is the full image size.\n",
    "    - $w = \\frac{1}{n}$ is the size of one pixel of the full resolution image.\n",
    "\n",
    "## Mip-map levels\n",
    "\n",
    "The number of mip-map levels is:\n",
    "\n",
    "$$N = \\lfloor \\log_2 n \\rfloor + 1$$\n",
    "\n",
    "The resolution of each level is, with $k = 0$ the full resolution one:\n",
    "\n",
    "$$n_k = \\lfloor \\frac{n} {2^k} \\rfloor$$\n",
    "\n",
    "If $n$ is a power of 2, then this is obviously correct, for example with $n = 16$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "N &= 4 + 1 = 5\\\\\n",
    "n_k &= 16, 8, 4, 2, 1\n",
    "\\end{align*}$$\n",
    "\n",
    "If $n$ is not a power of 2, then this still works, for example with $n = 15$ [Guthe2005]:\n",
    "\n",
    "$$\\begin{align*}\n",
    "N &= 3 + 1 = 4\\\\\n",
    "n_k &= 15, \\lfloor\\frac{15}{2}\\rfloor = 7, \\lfloor\\frac{15}{4}\\rfloor = 3, \\lfloor\\frac{15}{8}\\rfloor = 1\n",
    "\\end{align*}$$\n",
    "\n",
    "[Guthe2005] Guthe, S., and P. Heckbert 2005. Non-power-of-two Mipmap creation. NVIDIA Technical Report. https://download.nvidia.com/developer/Papers/2005/NP2_Mipmapping/NP2_Mipmap_Creation.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for n in range(1, 17):\n",
    "    N = int(math.floor(math.log2(n))) + 1\n",
    "    n_k = [int(math.floor(n / (2**k))) for k in range(N)]\n",
    "    print(f\"n={n}: N={N}, n_k={n_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trilinear mip-mapping\n",
    "\n",
    "To select the right mip-map level, we take $\\log_2 w$ and we add it to the $1 \\times 1$ mip-map level $(N - 1)$.\n",
    "\n",
    "$$k = (N - 1) + \\log_2 w$$\n",
    "\n",
    "- If $w = 1$, we're basically want to sample the whole image and we need to most coarse mip-map level. Indeed, $\\log_2 w = 0$ and we get $k = N - 1$.\n",
    "- If $w = \\frac{1}{n}$, then the sample size is the size of one pixel of the full-resolution image,\n",
    "  and we want the top-level image. Indeed, $\\log_2 w = -(N - 1)$ and we get $k = 0$.\n",
    "\n",
    "To evaluate $f_k(u, v)$, we blend between two mip-map levels:\n",
    "\n",
    "$$f_k(u, v) = \\begin{cases}\n",
    "    (1 - \\delta k) f_{k_0}(u, v) + \\delta k f_{k_1}(u, v) & \\text{if } k \\in [0, N - 1)\\\\\n",
    "    f_0(u, v) & \\text{if } k < 0 \\\\\n",
    "    f_{N-1}(u, v) & \\text{if } k \\geq N - 1 \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\\begin{align*}k_0 &= \\lfloor k \\rfloor \\\\\n",
    "    k_1 &= \\lceil k \\rceil \\\\\n",
    "    \\delta k &= k - k_0\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast $\\log_2$ approximation\n",
    "\n",
    "Assume $w > 0$ is a normalized single-precision floating point value. It's binary representation is:\n",
    "\n",
    "$$w = {-1}^s \\cdot 2^e \\cdot m$$\n",
    "\n",
    "with:\n",
    "\n",
    "- $s \\in \\{0, 1\\}$: the sign bit: 0 if $w > 0$, 1 if $w < 0$\n",
    "- $e$: integer exponent\n",
    "- $m \\in \\left[ 1, 2 \\right)$: is the significand.\n",
    "\n",
    "Because $w > 0$, we can simplify this to:\n",
    "\n",
    "$$w = 2^e \\cdot m$$\n",
    "\n",
    "Taking $\\log_2$ becomes:\n",
    "\n",
    "$$\\begin{align*}\\log_2(w) \n",
    "    &= \\log_2 \\left( 2^e \\cdot m \\right)\\\\\n",
    "    &= \\log_2 \\left( 2^e \\right) + \\log_2 m\\\\\n",
    "    &= e + \\log_2 m\n",
    "\\end{align*}$$\n",
    "\n",
    "We know that $e$ is integer, and:\n",
    "\n",
    "$$m \\in \\left[ 1, 2 \\right) \\\\\n",
    "\\Downarrow \\\\\n",
    "\\log_2 m \\in \\left[0, 1\\right)$$\n",
    "\n",
    "We finally get that:\n",
    "\n",
    "$$\\begin{align*}k_0 &= e \\\\\n",
    "    k_1 &= e + 1 \\\\\n",
    "    \\delta k &= \\log_2 m\n",
    "\\end{align*}$$\n",
    "\n",
    "Then, we finally make a very crude approximation:\n",
    "\n",
    "$$\\delta k = \\log_2 m \\approx m - 1$$\n",
    "\n",
    "It's a very crude approximation as you can see in the plot below.\n",
    "The maximimum absolute error is 0.086 and the maximum relative error is 31%.\n",
    "But for blending between to mip-map levels this is perfectly adequate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "m = np.arange(1, 2, 0.001)\n",
    "dk = np.log2(m)\n",
    "dk_fast = m - 1\n",
    "abs_err = np.abs(dk - dk_fast)\n",
    "\n",
    "print(f\"max absolute error: {np.max(abs_err):.2f}\")\n",
    "\n",
    "plt.plot(m, dk, label=\"$log_2 m$\")\n",
    "plt.plot(m, dk_fast, label=\"$m-1$\")\n",
    "plt.plot(m, abs_err, label=\"abs err\")\n",
    "plt.xlabel(\"$m$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "To implement the fast $\\log_2$ approximation, we first need to reinterpret the\n",
    "single precision $w$ as a 32-bit integer `i` [wiki]:\n",
    "\n",
    "```\n",
    "b = float2bits(w)\n",
    "```\n",
    "\n",
    "- The most significant bit is the sign bit, which is 0 ($w > 0$)\n",
    "- Then we have 8 exponent bits, which stores the exponent with a bias of 127, thus $e + 127$\n",
    "- Then the 23 least significant bits store the fraction of the significand $m$, the 1 before\n",
    "  the decimal point is not stored.\n",
    "\n",
    "To extract $e$, we can simply bit-shift out the significand and subtract the bias. \n",
    "We don't need to make the sign bit, as it's always 0 ($w > 0$):\n",
    "\n",
    "```\n",
    "e = (b >> 23) - 127\n",
    "```\n",
    "\n",
    "To extract $m$, we set the exponent to zero, and reinterpret the result again as a floating point value.\n",
    "We first need to mask out the original exponent, and then replace it by the bias 127,\n",
    "shifted 23 bits to the left:\n",
    "\n",
    "```\n",
    "m = bits2float((127 << 23) | (b & 0x7fffff))\n",
    "```\n",
    "\n",
    "[wiki] Wikipedia contributors. (2025, January 11). Single-precision floating-point format. In Wikipedia, The Free Encyclopedia. Retrieved 17:57, February 28, 2025, from https://en.wikipedia.org/w/index.php?title=Single-precision_floating-point_format&oldid=1268685998\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "\n",
    "def float2bits(w: float):\n",
    "    return struct.unpack(\"I\", struct.pack(\"f\", w))[0]\n",
    "\n",
    "\n",
    "def bits2float(w: float):\n",
    "    return struct.unpack(\"f\", struct.pack(\"I\", w))[0]\n",
    "\n",
    "\n",
    "def fast_log2(w: float):\n",
    "    assert w > 0\n",
    "    b = float2bits(w)\n",
    "    e = (b >> 23) - 127\n",
    "    m = bits2float((127 << 23) | (b & 0x7FFFFF))\n",
    "    return e + (m - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.arange(0.1, 1, 0.001)\n",
    "\n",
    "k = np.log2(w)\n",
    "k_fast = [fast_log2(x) for x in w]\n",
    "\n",
    "plt.plot(w, k, label=\"log2\")\n",
    "plt.plot(w, k_fast, label=\"fastlog2\")\n",
    "plt.xlabel(\"$w$\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(w, np.abs(k - k_fast), label=\"abs err\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$w$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
